{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          aten::normal_        37.32%      35.994ms        37.32%      35.994ms       1.800ms            20  \n",
      "                                         aten::uniform_        30.31%      29.234ms        30.31%      29.234ms       1.218ms            24  \n",
      "                            aten::_slow_conv2d_backward        11.50%      11.092ms        13.08%      12.611ms     663.737us            19  \n",
      "                             aten::_slow_conv2d_forward         4.21%       4.064ms         4.31%       4.154ms     218.632us            19  \n",
      "                                            aten::copy_         2.51%       2.418ms         2.51%       2.418ms      36.090us            67  \n",
      "                                             aten::add_         2.02%       1.944ms         2.02%       1.944ms      19.837us            98  \n",
      "                               aten::threshold_backward         1.54%       1.482ms         1.54%       1.482ms      87.176us            17  \n",
      "                                            aten::fill_         1.36%       1.310ms         1.36%       1.310ms      10.650us           123  \n",
      "                                Optimizer.step#SGD.step         1.25%       1.207ms         6.02%       5.806ms       5.806ms             1  \n",
      "                                aten::native_batch_norm         1.02%     979.000us         1.18%       1.142ms      57.100us            20  \n",
      "                             aten::convolution_backward         0.50%     487.000us        13.59%      13.104ms     655.200us            20  \n",
      "                                            aten::empty         0.48%     459.000us         0.48%     459.000us       0.989us           464  \n",
      "                       aten::native_batch_norm_backward         0.46%     443.000us         0.72%     691.000us      34.550us            20  \n",
      "autograd::engine::evaluate_function: ConvolutionBack...         0.36%     343.000us        14.19%      13.689ms     684.450us            20  \n",
      "                               aten::mkldnn_convolution         0.34%     325.000us         0.35%     333.000us     333.000us             1  \n",
      "                                               aten::mm         0.33%     323.000us         0.36%     346.000us     173.000us             2  \n",
      "                                            aten::clone         0.31%     297.000us         2.93%       2.823ms      44.109us            64  \n",
      "                                           aten::detach         0.27%     264.000us         0.49%     474.000us       2.548us           186  \n",
      "                                      aten::convolution         0.25%     239.000us         5.12%       4.939ms     246.950us            20  \n",
      "                                                 detach         0.24%     227.000us         0.24%     227.000us       1.220us           186  \n",
      "                                            aten::addmm         0.22%     215.000us         0.23%     220.000us     220.000us             1  \n",
      "                                       aten::empty_like         0.21%     204.000us         0.32%     313.000us       4.968us            63  \n",
      "autograd::engine::evaluate_function: NativeBatchNorm...         0.21%     198.000us         1.08%       1.039ms      51.950us            20  \n",
      "                        torch::autograd::AccumulateGrad         0.19%     181.000us         0.34%     332.000us       5.355us            62  \n",
      "                                            aten::relu_         0.16%     156.000us         0.32%     310.000us      18.235us            17  \n",
      "autograd::engine::evaluate_function: torch::autograd...         0.16%     156.000us         0.51%     493.000us       7.952us            62  \n",
      "                                       aten::clamp_min_         0.16%     154.000us         0.16%     154.000us       9.059us            17  \n",
      "                                     aten::_convolution         0.16%     151.000us         4.87%       4.700ms     235.000us            20  \n",
      "                               NativeBatchNormBackward0         0.16%     150.000us         0.87%     841.000us      42.050us            20  \n",
      "                                          aten::resize_         0.15%     149.000us         0.15%     149.000us       2.525us            59  \n",
      "                           aten::_batch_norm_impl_index         0.15%     149.000us         1.36%       1.308ms      65.400us            20  \n",
      "                          aten::max_pool2d_with_indices         0.15%     147.000us         0.15%     147.000us     147.000us             1  \n",
      "                                   ConvolutionBackward0         0.14%     138.000us        13.73%      13.242ms     662.100us            20  \n",
      "                                    aten::empty_strided         0.13%     126.000us         0.13%     126.000us       1.938us            65  \n",
      "                                            aten::zero_         0.10%      99.000us         1.34%       1.292ms      10.857us           119  \n",
      "                                          ReluBackward0         0.09%      86.000us         1.63%       1.568ms      92.235us            17  \n",
      "                                             aten::view         0.08%      81.000us         0.08%      81.000us       1.350us            60  \n",
      "     autograd::engine::evaluate_function: ReluBackward0         0.08%      77.000us         1.71%       1.645ms      96.765us            17  \n",
      "                                           aten::conv2d         0.08%      76.000us         5.20%       5.015ms     250.750us            20  \n",
      "                                             aten::ones         0.06%      62.000us         0.10%      96.000us       4.800us            20  \n",
      "                                      aten::thnn_conv2d         0.06%      62.000us         4.37%       4.216ms     221.895us            19  \n",
      "                                       aten::batch_norm         0.06%      59.000us         1.42%       1.367ms      68.350us            20  \n",
      "                                            aten::zeros         0.06%      54.000us         0.06%      57.000us       2.850us            20  \n",
      "                                              aten::sum         0.06%      54.000us         0.06%      59.000us      19.667us             3  \n",
      "                                       aten::resize_as_         0.04%      38.000us         0.07%      69.000us       3.632us            19  \n",
      "      autograd::engine::evaluate_function: AddBackward0         0.03%      29.000us         0.04%      36.000us       4.500us             8  \n",
      "                                         AddmmBackward0         0.02%      20.000us         0.40%     387.000us     387.000us             1  \n",
      "                                              aten::div         0.02%      17.000us         0.03%      25.000us      25.000us             1  \n",
      "                                                aten::t         0.02%      16.000us         0.04%      34.000us       6.800us             5  \n",
      "                 aten::max_pool2d_with_indices_backward         0.02%      16.000us         0.03%      32.000us      32.000us             1  \n",
      "                                              aten::sub         0.02%      15.000us         0.02%      15.000us      15.000us             1  \n",
      "                                        aten::transpose         0.01%      14.000us         0.02%      18.000us       3.600us             5  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.01%      14.000us         0.43%     418.000us     418.000us             1  \n",
      "                                             aten::mean         0.01%      11.000us         0.06%      59.000us      59.000us             1  \n",
      "                                           aten::expand         0.01%      11.000us         0.01%      12.000us       4.000us             3  \n",
      "                                          aten::detach_         0.01%      10.000us         0.01%      10.000us       0.500us            20  \n",
      "                                             aten::div_         0.01%      10.000us         0.03%      25.000us      25.000us             1  \n",
      "                                         aten::_to_copy         0.01%      10.000us         0.02%      20.000us      10.000us             2  \n",
      "                                             aten::rand         0.01%       9.000us         0.05%      53.000us      26.500us             2  \n",
      "                                      aten::as_strided_         0.01%       8.000us         0.01%       8.000us       4.000us             2  \n",
      "                                           AddBackward0         0.01%       7.000us         0.01%       7.000us       0.875us             8  \n",
      "autograd::engine::evaluate_function: MaxPool2DWithIn...         0.01%       7.000us         0.05%      45.000us      45.000us             1  \n",
      "                                           aten::linear         0.01%       6.000us         0.24%     236.000us     236.000us             1  \n",
      "                                       aten::as_strided         0.01%       6.000us         0.01%       6.000us       0.667us             9  \n",
      "                          MaxPool2DWithIndicesBackward0         0.01%       6.000us         0.04%      38.000us      38.000us             1  \n",
      "      autograd::engine::evaluate_function: SumBackward0         0.01%       5.000us         0.02%      15.000us      15.000us             1  \n",
      "                                       aten::max_pool2d         0.00%       4.000us         0.16%     151.000us     151.000us             1  \n",
      "                                        aten::ones_like         0.00%       4.000us         0.01%       9.000us       9.000us             1  \n",
      "                                          MeanBackward1         0.00%       4.000us         0.03%      32.000us      32.000us             1  \n",
      "                                               aten::to         0.00%       3.000us         0.02%      23.000us       1.045us            22  \n",
      "                              aten::adaptive_avg_pool2d         0.00%       3.000us         0.06%      62.000us      62.000us             1  \n",
      "                                          aten::flatten         0.00%       3.000us         0.01%       9.000us       9.000us             1  \n",
      "                                           SumBackward0         0.00%       3.000us         0.01%      10.000us      10.000us             1  \n",
      "      autograd::engine::evaluate_function: SubBackward0         0.00%       3.000us         0.00%       3.000us       3.000us             1  \n",
      "        autograd::engine::evaluate_function: TBackward0         0.00%       3.000us         0.01%       7.000us       7.000us             1  \n",
      "                                          ViewBackward0         0.00%       2.000us         0.00%       4.000us       4.000us             1  \n",
      "     autograd::engine::evaluate_function: MeanBackward1         0.00%       2.000us         0.04%      34.000us      34.000us             1  \n",
      "                                             TBackward0         0.00%       1.000us         0.00%       4.000us       4.000us             1  \n",
      "     autograd::engine::evaluate_function: ViewBackward0         0.00%       1.000us         0.01%       5.000us       5.000us             1  \n",
      "                                          aten::reshape         0.00%       1.000us         0.00%       2.000us       2.000us             1  \n",
      "                                       aten::lift_fresh         0.00%       0.000us         0.00%       0.000us       0.000us            20  \n",
      "                                                detach_         0.00%       0.000us         0.00%       0.000us       0.000us            20  \n",
      "                                     aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us             6  \n",
      "                                           SubBackward0         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 96.437ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from torch.autograd import profiler\n",
    "with profiler.profile(record_shapes=True) as prof:\n",
    "\n",
    "    # Load pretrained ResNet18 model\n",
    "    model = resnet18()\n",
    "\n",
    "    # Create random input data (image) and labels\n",
    "    data = torch.rand(1, 3, 64, 64)\n",
    "    labels = torch.rand(1, 1000)\n",
    "\n",
    "    # Forward pass: Make a prediction\n",
    "    prediction = model(data)\n",
    "\n",
    "    # Calculate error (loss)\n",
    "    loss = (prediction - labels).sum()\n",
    "\n",
    "    # Backward pass: Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Initialize optimizer (SGD with lr=0.01 and momentum=0.9)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "    # Update parameters using gradient descent\n",
    "    optimizer.step()\n",
    "    \n",
    "    pass\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_dot\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m make_dot(y, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters()))\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple_nn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\240714_UsingPythonForResearch\\2021_DLwithPython\\deep-learning-python-2e\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 784]"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "x = torch.randn(1, 28 * 28)\n",
    "y = model(x)\n",
    "make_dot(y, params=dict(model.named_parameters())).render(\"simple_nn\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
