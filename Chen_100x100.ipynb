{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copilot\n",
    "That makes sense! In direction finding (DF) applications, increasing the number of grid points indeed improves the resolution, allowing for more precise angle estimation. Here’s a breakdown of what you’re describing:\n",
    "\n",
    "Grid Points Calculation:\n",
    "If you use 10 grid points for each angle (theta and phi), you get (10 \\times 10 = 100) grid points.\n",
    "If you use 100 grid points for each angle, you get (100 \\times 100 = 10,000) grid points.\n",
    "\n",
    "Classification Task:\n",
    "Each grid point represents a unique class that the model needs to classify. So, with 100 grid points, you have 100 classes, and with 10,000 grid points, you have 10,000 classes.\n",
    "Practical Considerations\n",
    "Model Complexity: With 10,000 classes, the model will need to be quite complex to accurately classify each grid point.\n",
    "Data Requirements: You’ll need a substantial amount of training data to ensure each class is well-represented.\n",
    "Computational Resources: Training and inference will require significant computational power and memory.\n",
    "Example\n",
    "Here’s a simplified example of how you might set up a neural network for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# class DFNet(nn.Module):\n",
    "#     def __init__(self, num_classes=10000):\n",
    "#         super().__init__()\n",
    "#         self.conv_unit_1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         )\n",
    "#         # Additional layers would go here\n",
    "#         self.fc = nn.Linear(16 * 14 * 14, num_classes)  # Adjust dimensions as needed\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_unit_1(x)\n",
    "#         # Pass through additional layers\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = self.fc(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 16 different 3x3 filters in a convolutional layer are not manually defined; they are learned automatically during the training process of the neural network. Here’s how it works:\n",
    "\n",
    "Initialization\n",
    "When you initialize the convolutional layer, the filters (weights) are typically set to small random values. This randomness helps in breaking symmetry and ensures that each filter starts learning different features.\n",
    "Training Process\n",
    "Forward Pass:\n",
    "During the forward pass, the input image is convolved with the filters to produce feature maps. These feature maps are then passed through the rest of the network.\n",
    "Loss Calculation:\n",
    "The network’s output is compared to the ground truth labels using a loss function (e.g., cross-entropy loss for classification tasks). The loss function measures how far the network’s predictions are from the actual labels.\n",
    "Backpropagation:\n",
    "The loss is propagated back through the network using a process called backpropagation. This involves calculating the gradient of the loss with respect to each filter’s weights.\n",
    "Weight Update:\n",
    "The filters are updated using an optimization algorithm (e.g., stochastic gradient descent, Adam). The weights are adjusted in the direction that reduces the loss, allowing the filters to learn useful features.\n",
    "Iterative Learning\n",
    "This process is repeated over many iterations (epochs) with different batches of training data. Over time, the filters learn to detect various features that are important for the classification task.\n",
    "Example\n",
    "Let’s say you have a filter initialized with random values. During training, this filter might start detecting simple patterns like edges. As training progresses, the filter’s weights are adjusted to detect more complex patterns and features relevant to the task.\n",
    "\n",
    "Visualization\n",
    "Researchers often visualize the learned filters to understand what features the network is focusing on. Early layers might learn to detect edges and textures, while deeper layers might learn more complex patterns like shapes or even parts of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copilot\n",
    "Sure! Let’s walk through a comprehensive example of how filters are learned in a convolutional neural network (CNN) using PyTorch. We’ll create a simple CNN, train it on a dataset, and visualize the learned filters\n",
    "\n",
    "### Step 1: Import Libraries\n",
    "First, we’ll import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Importing torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the CNN\n",
    "We’ll define a simple CNN with one convolutional layer to keep things straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 14 * 14, 10)  # Assuming input size is 28x28\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 14 * 14)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load the Dataset\n",
    "We’ll use the MNIST dataset for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model\n",
    "We’ll define the training loop and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(2):  # Train for 2 epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Visualize the Learned Filters\n",
    "After training, we can visualize the filters learned by the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone()\n",
    "    filters = filters - filters.min()\n",
    "    filters = filters / filters.max()\n",
    "    filter_grid = torchvision.utils.make_grid(filters, nrow=4, padding=1)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(filter_grid.permute(1, 2, 0))\n",
    "    plt.title('Learned Filters')\n",
    "    plt.show()\n",
    "\n",
    "visualize_filters(net.conv1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "Initialization: The filters are initialized with random values.\n",
    "Training: During training, the filters are adjusted to minimize the loss function. This process allows the filters to learn features from the input data.\n",
    "Visualization: After training, we visualize the filters to see what features they have learned. Each filter will highlight different aspects of the input images, such as edges or textures.\n",
    "This example demonstrates how filters in a CNN are learned and how you can visualize them to understand what the network is focusing on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
